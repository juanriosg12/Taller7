{"cells":[{"cell_type":"markdown","metadata":{"id":"_Hq739EyGb3y"},"source":["## Taller 7"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XvZd5CxTGdcd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import keras"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Set random seeds for reproducibility\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","# Set the environment flag for determinism\n","tf.config.experimental.enable_op_determinism()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"SrWIjZxQG-Pm"},"outputs":[],"source":["df = pd.read_csv('heart.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VjBQLhr3INGC"},"outputs":[],"source":["df.head()"]},{"cell_type":"markdown","metadata":{"id":"Sf3tQ4SdKQy7"},"source":["Descripción de las variables:\n","\n","https://archive.ics.uci.edu/dataset/45/heart+disease\n"]},{"cell_type":"markdown","metadata":{"id":"GRDlL9vAJAz1"},"source":["Exploremos el tamaño del df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PeHyTPnEJC8f"},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"id":"dONjz931JFhG"},"source":["Identificamos NAs en los datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47pvp0jtJFKt"},"outputs":[],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"Ebb_FtLdmEgT"},"source":["Definimos listas para las variables categóricas enteras, categóricas string y numéricas."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"U6HARyge_bKP"},"outputs":[],"source":["## Reducimos el numero de variables categoricas a 4\n","cat_int_feats = ['sex', 'cp', 'fbs', 'exang']"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"onEA7I5N_ek0"},"outputs":[],"source":["cat_str_feats = ['thal']"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"YxwNz_7y_hrv"},"outputs":[],"source":["# Reducimos el numero de variables numericas a 4\n","num_feats = ['age', 'chol', 'oldpeak', 'slope']"]},{"cell_type":"markdown","metadata":{"id":"hL-Zip0OmNru"},"source":["Agregamos las listas de categorías"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"DBzj4Qxr_kR1"},"outputs":[],"source":["feats_ordered = cat_int_feats+cat_str_feats+num_feats"]},{"cell_type":"markdown","metadata":{"id":"P_Mlzsv9mRH3"},"source":["Reordenamos el dataframe de acuerdo con el tipo de variable"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"yH8Xsu1a_ohM"},"outputs":[],"source":["df = df[feats_ordered+['target']]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QY-c3kZD_paR"},"outputs":[],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df[\"target\"].unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.dtypes"]},{"cell_type":"markdown","metadata":{"id":"8Ls8L1hRMQh4"},"source":["Separamos los datos en entrenamiento, validación y prueba"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8dADsWjtMTcS"},"outputs":[],"source":["train = df.sample(frac=0.8, random_state=100)\n","train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZOQNUy2jSwH"},"outputs":[],"source":["train.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TC9xJuiKMenc"},"outputs":[],"source":["test = df.drop(train.index)\n","test.head()"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"z3Bmb1Npj_zu"},"outputs":[],"source":["val = train.sample(frac=0.2, random_state=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfSRCJElkP4U"},"outputs":[],"source":["val.shape"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"_Ptvi_pBkImU"},"outputs":[],"source":["train = train.drop(val.index)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-H2PITXhMmcz"},"outputs":[],"source":["print(train.shape)\n","print(val.shape)\n","print(test.shape)"]},{"cell_type":"markdown","metadata":{"id":"t58x12kjNrK7"},"source":["Calculamos estadísticas de cada variable numérica"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ycw_T_PnNtmr"},"outputs":[],"source":["train.describe()"]},{"cell_type":"markdown","metadata":{"id":"O0kwTMsxPEC-"},"source":["Función para convertir de dataframe (pandas) a dataset (tensorflow), separando características y etiquetas"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"2mMPXHVzty85"},"outputs":[],"source":["def dataframe_to_dataset(dataframe):\n","    dataframe = dataframe.copy()\n","    labels = dataframe.pop(\"target\")\n","    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n","    ds = ds.shuffle(buffer_size=len(dataframe))\n","    return ds"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"ajCnnkOvt2yZ"},"outputs":[],"source":["train_ds = dataframe_to_dataset(train)\n","val_ds = dataframe_to_dataset(val)\n","test_ds = dataframe_to_dataset(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JWOTIj3MuFHT"},"outputs":[],"source":["type(train_ds)"]},{"cell_type":"markdown","metadata":{"id":"OzN2TbxKmv5J"},"source":["Ejemplo de cómo queda el tf.dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Kis1GC_uP94"},"outputs":[],"source":["for x, y in train_ds.take(1):\n","    print(\"Input:\", x)\n","    print(\"Target:\", y)"]},{"cell_type":"markdown","metadata":{"id":"fqfXQMammzE5"},"source":["Separamos los datos de entrenamiento, validación y prueba en lotes"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"qYSJR321ucz4"},"outputs":[],"source":["batch_size = 32\n","train_ds = train_ds.batch(batch_size)\n","test_ds = test_ds.batch(batch_size)\n","val_ds = val_ds.batch(batch_size)"]},{"cell_type":"markdown","metadata":{"id":"gekvkTr8vem7"},"source":["Función para codificar variables numéricas (Keras docs)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"lHL-Xz2vvcPz"},"outputs":[],"source":["def encode_numerical_feature(feature, name, dataset):\n","    # Crea capa de normalización para este feature\n","    normalizer = keras.layers.Normalization()\n","\n","    # Prepara el dataset para considerar únicamente la feature de interés (name)\n","    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n","    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n","\n","    # Aprende las estadísticas de los datos (media, varianza)\n","    normalizer.adapt(feature_ds)\n","\n","    # Aplica la normalización a la variable\n","    encoded_feature = normalizer(feature)\n","    return encoded_feature"]},{"cell_type":"markdown","metadata":{"id":"-2egk2GMvrYW"},"source":["Función para codificar variables categóricas (Keras docs)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"o6XFsdP3vxI4"},"outputs":[],"source":["def encode_categorical_feature(feature, name, dataset, is_string):\n","    lookup_class = keras.layers.StringLookup if is_string else keras.layers.IntegerLookup\n","    # Crea una capa Lookup para retornas variables 0/1 (dummies)\n","    # lookup: busca el valor correspondiente de la variable categórica\n","    lookup = lookup_class(output_mode=\"binary\")\n","\n","    # Prepara el dataset para considerar únicamente la feature de interés (name)\n","    feature_ds = dataset.map(lambda x, y: x[name]) # selecciona variable\n","    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1)) # deja el tensor de una dimensión\n","\n","    # Aprende el conjunto de posibles valores que toma la variable categórica y asigna enteros\n","    lookup.adapt(feature_ds)\n","\n","    # Aplica la conversión de categorías a enteros\n","    encoded_feature = lookup(feature)\n","    return encoded_feature"]},{"cell_type":"markdown","metadata":{"id":"pxFez9T6ib3x"},"source":["Creamos una lista de inputs para el modelo, de acuerdo con cada tipo de variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qe4JwN9Jv4g8"},"outputs":[],"source":["inputs = []\n","for i in cat_int_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"int64\"))"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"8My9fdD9wdpO"},"outputs":[],"source":["for i in cat_str_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i, dtype=\"string\"))"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"6smPNUmwwpC0"},"outputs":[],"source":["for i in num_feats:\n","  inputs.append(keras.Input(shape=(1,), name=i))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iViUbLxzwyqK"},"outputs":[],"source":["for i in inputs:\n","   print(i)"]},{"cell_type":"markdown","metadata":{"id":"QNRJIbFhihq1"},"source":["Creamos una lista de variables codificadas/normalizadas de acuerdo con su tipo, empleando las funciones de codificación/normalización"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"QZFZk7n1w18S"},"outputs":[],"source":["feats_encoded=[]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNsjUGDyxEFU"},"outputs":[],"source":["for i,feat in enumerate(cat_int_feats):\n","  feats_encoded.append(\n","      encode_categorical_feature(inputs[i], feat, train_ds, False)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NoGZIhI5yNF8"},"outputs":[],"source":["len_feats = len(feats_encoded)\n","len_feats"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"f4FB7nNZyMla"},"outputs":[],"source":["for i,feat in enumerate(cat_str_feats):\n","  feats_encoded.append(\n","      encode_categorical_feature(inputs[len_feats+i], feat, train_ds, True)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQx1yyshykyC"},"outputs":[],"source":["len_feats = len(feats_encoded)\n","len_feats"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"uW6cMxRmyoPq"},"outputs":[],"source":["for i,feat in enumerate(num_feats):\n","  feats_encoded.append(\n","      encode_numerical_feature(inputs[len_feats+i], feat, train_ds)\n","  )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8787d5HzklR"},"outputs":[],"source":["for i in feats_encoded:\n","  print(i)"]},{"cell_type":"markdown","metadata":{"id":"O7Wkmq4_iu7C"},"source":["Creamos una capa concatenando todas las variables codificadas"]},{"cell_type":"code","execution_count":42,"metadata":{"id":"MnCXNQmVzvFo"},"outputs":[],"source":["all_feats = keras.layers.concatenate(feats_encoded)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaQ-LGQ-z1dZ"},"outputs":[],"source":["type(all_feats)"]},{"cell_type":"markdown","metadata":{"id":"jJDu5_h4i5K2"},"source":["Agregamos una capa densa con 32 neuronas y función de activación relu"]},{"cell_type":"code","execution_count":44,"metadata":{"id":"9fQNOhhC0UKq"},"outputs":[],"source":["model_layers = keras.layers.Dense(32, activation='relu')(all_feats)"]},{"cell_type":"markdown","metadata":{"id":"VpOkMLORjBus"},"source":["Agregamos la capa de salida con 1 neurona (probabilidad de sufrir la enfermedad cardiada) y función de activación sigmoide"]},{"cell_type":"code","execution_count":45,"metadata":{"id":"-hJ3U5gg0cRa"},"outputs":[],"source":["model_layers = keras.layers.Dense(1, activation='sigmoid')(model_layers)"]},{"cell_type":"markdown","metadata":{"id":"UE2Q7SqsjOZX"},"source":["Creamos el modelo con las capas ya creadas y las variables de entrada"]},{"cell_type":"code","execution_count":46,"metadata":{"id":"hcQSv0j2z58b"},"outputs":[],"source":["model = keras.Model(inputs, model_layers)"]},{"cell_type":"markdown","metadata":{"id":"ZNagIagJjXNG"},"source":["Compilamos el modelo, definiendo optimizador, función de pérdida y métricas adicionales a capturar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mkx1iu9i0qZR"},"outputs":[],"source":["model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLhp4Tdf1jPM"},"outputs":[],"source":["keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"]},{"cell_type":"markdown","metadata":{"id":"boQih7bljscZ"},"source":["Aseguramos que Keras use TensorFlow como backend, para asegurar que el modelo pueda usar strings como entradas"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"K_mKv-Bn6h4H"},"outputs":[],"source":["import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.summary()"]},{"cell_type":"markdown","metadata":{"id":"z-2-ELq4jtdb"},"source":["Entrenamos el modelo con los datos en el formato tf.Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DebRVUwi04dx"},"outputs":[],"source":["history = model.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['loss'], label='loss')\n","plt.plot(history.history['val_loss'], label='val_loss')\n","# plt.plot(history.history['accuracy'],label='accuracy')\n","# plt.plot(history.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Modelo base\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# plt.plot(history.history['loss'], label='loss')\n","# plt.plot(history.history['val_loss'], label='val_loss')\n","plt.plot(history.history['accuracy'],label='accuracy')\n","plt.plot(history.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Modelo base\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results = model.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados para modelo base\")\n","for name, value in zip(model.metrics_names, results):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 3 - 1 (optimizador = SGD)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["from tensorflow.keras.optimizers import SGD, Adam, RMSprop"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["optimizer_exp1 = SGD(learning_rate=0.01, momentum=0.9)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["model_exp1 = keras.Model(inputs, model_layers)"]},{"cell_type":"markdown","metadata":{},"source":["Compilamos el modelo, definiendo optimizador, función de pérdida y métricas adicionales a capturar"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["model_exp1.compile(optimizer=optimizer_exp1, loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["keras.utils.plot_model(model_exp1, show_shapes=True, rankdir=\"LR\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_exp1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_exp1 = model_exp1.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_exp1.history['loss'], label='loss')\n","plt.plot(history_exp1.history['val_loss'], label='val_loss')\n","# plt.plot(history.history['accuracy'],label='accuracy')\n","# plt.plot(history.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 3 - 1 SGD\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# plt.plot(history.history['loss'], label='loss')\n","# plt.plot(history.history['val_loss'], label='val_loss')\n","plt.plot(history_exp1.history['accuracy'],label='accuracy')\n","plt.plot(history_exp1.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 3 - 1 SGD\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_exp1 = model_exp1.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 3 - 1 SGD\")\n","for name, value in zip(model_exp1.metrics_names, results_exp1):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 3 - 2 (RMS)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["optimizer_exp2 = RMSprop(learning_rate=0.001)"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[],"source":["model_exp2 = keras.Model(inputs, model_layers)"]},{"cell_type":"markdown","metadata":{},"source":["Compilamos el modelo, definiendo optimizador, función de pérdida y métricas adicionales a capturar"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[],"source":["model_exp2.compile(optimizer=optimizer_exp2, loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_exp2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_exp2 = model_exp2.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_exp2.history['loss'], label='loss')\n","plt.plot(history_exp2.history['val_loss'], label='val_loss')\n","# plt.plot(history.history['accuracy'],label='accuracy')\n","# plt.plot(history.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 3 - 2 RMS\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# plt.plot(history.history['loss'], label='loss')\n","# plt.plot(history.history['val_loss'], label='val_loss')\n","plt.plot(history_exp2.history['accuracy'],label='accuracy')\n","plt.plot(history_exp2.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 3 - 2 RMS\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_exp2 = model_exp2.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 3 - 2 RMS\")\n","for name, value in zip(model_exp2.metrics_names, results_exp1):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 4 - 1 (tasa = 0.01)"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["model_4_1 = keras.Model(inputs, model_layers)"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["learning_rate_1 = 0.01\n","optimizer = Adam(learning_rate=learning_rate_1)\n","model_4_1.compile(optimizer=optimizer, loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_4_1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_4_1 = model_4_1.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_1.history['loss'], label='loss')\n","plt.plot(history_4_1.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 4 - 1 (0.01)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_1.history['accuracy'],label='accuracy')\n","plt.plot(history_4_1.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 4 - 1 (0.01)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_4_1 = model_4_1.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 4 - 1 (0.01)\")\n","for name, value in zip(model_4_1.metrics_names, results_4_1):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 4 - 2 (tasa = 0.0001)"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["model_4_2 = keras.Model(inputs, model_layers)"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["learning_rate_2 = 0.0001\n","optimizer = Adam(learning_rate=learning_rate_2)\n","model_4_2.compile(optimizer=optimizer, loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_4_2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_4_2 = model_4_2.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_2.history['loss'], label='loss')\n","plt.plot(history_4_2.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 4 - 2 (0.0001)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_2.history['accuracy'],label='accuracy')\n","plt.plot(history_4_2.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 4 - 2 (0.0001)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_4_2 = model_4_2.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 4 - 2 (0.0001)\")\n","for name, value in zip(model_4_2.metrics_names, results_4_2):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 4 - 3 (tasa = 0.005)"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[],"source":["model_4_3 = keras.Model(inputs, model_layers)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["learning_rate_3 = 0.005\n","optimizer = Adam(learning_rate=learning_rate_3)\n","model_4_3.compile(optimizer=optimizer, loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_4_3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_4_3 = model_4_3.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_3.history['loss'], label='loss')\n","plt.plot(history_4_3.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 4 - 3 (0.005)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_4_3.history['accuracy'],label='accuracy')\n","plt.plot(history_4_3.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 4 - 3 (0.005)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_4_3 = model_4_3.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 4 - 3 (0.005)\")\n","for name, value in zip(model_4_3.metrics_names, results_4_3):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 6 - 1 (Tanh-sigmoid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_layers1 = keras.layers.Dense(32, activation='tanh')(all_feats)\n","model_layers1 = keras.layers.Dense(1, activation='sigmoid')(model_layers1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_1 = keras.Model(inputs, model_layers1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_1.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_1.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_6_1 = model_6_1.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_6_1.history['loss'], label='loss')\n","plt.plot(history_6_1.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 6 - 1 (tanh-sigmoid)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_6_1.history['accuracy'],label='accuracy')\n","plt.plot(history_6_1.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 6 - 1 (tanh-sigmoid)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_6_1 = model_6_1.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 6 - 1 (tanh-sigmoid)\")\n","for name, value in zip(model_6_1.metrics_names, results_6_1):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 6 - 2 (sigmoid-relu)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_layers2 = keras.layers.Dense(32, activation='sigmoid')(all_feats)\n","model_layers2 = keras.layers.Dense(1, activation='relu')(model_layers2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_2 = keras.Model(inputs, model_layers2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_2.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_2.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_6_2 = model_6_2.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(history_6_2.history['loss'], label='loss')\n","plt.plot(history_6_2.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 6 - 2 (sigmoid-relu)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_6_2.history['accuracy'],label='accuracy')\n","plt.plot(history_6_2.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 6 - 2 (sigmoid-relu)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_6_2 = model_6_2.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 6 - 2 (sigmoid-relu)\")\n","for name, value in zip(model_6_2.metrics_names, results_6_2):\n","    print(f\"{name}: {value}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Punto 6 - 3 (relu-tanh)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_layers3 = keras.layers.Dense(32, activation='relu')(all_feats)\n","model_layers3 = keras.layers.Dense(1, activation='tanh')(model_layers3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_3 = keras.Model(inputs, model_layers3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_3.compile(optimizer='adam', loss='binary_crossentropy',  metrics=[\"accuracy\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),tf.keras.metrics.AUC(name='roc_auc')])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_6_3.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["history_6_3 = model_6_3.fit(train_ds, epochs=50, validation_data=val_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(history_6_3.history['loss'], label='loss')\n","plt.plot(history_6_3.history['val_loss'], label='val_loss')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Function')\n","plt.title(\"Punto 6 - 3 (relu-tanh)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.plot(history_6_3.history['accuracy'],label='accuracy')\n","plt.plot(history_6_3.history['val_accuracy'],label='val_accuracy')\n","plt.ylim([0, 1])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.title(\"Punto 6 - 3 (relu-tanh)\")\n","plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["results_6_3 = model_6_3.evaluate(test_ds, verbose=0)\n","\n","# Assuming you have the metric names as defined in `model.metrics_names`\n","print(\"Resultados Punto 6 - 3(relu-tanh)\")\n","for name, value in zip(model_6_3.metrics_names, results_6_3):\n","    print(f\"{name}: {value}\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
